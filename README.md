# SpeakSafe AI

**One-line:**  
A simple web app that uses AI to detect online harassment, threats, or abusive messages toward women and girls and guides them on what to do next.

---

## ğŸš€ What is SpeakSafe AI?

SpeakSafe AI is a lightweight, web-based tool designed to empower women and girls by helping them understand if a message they received is abusive or harmful â€” and what to do about it.  
No bots, no complicated systems: just input â†’ AI detection â†’ guidance â†’ safe evidence storage.

---

## ğŸ’¡ The Problem

Many women and girls in online spaces face harassment, but they often donâ€™t know:

- Whether a message is just â€œnormal talkâ€ or is actually harmful  
- What next steps to take (report, block, reach out)  
- How to safely store proof of abuse  

SpeakSafe AI fills that gap by giving instant clarity and actionable advice.

---

## ğŸ§ª How It Works

1. A user pastes or types a message into a text box.  
2. The AI analyzes the message using a toxicity / harassment detection model.  
3. The app returns a result, indicating:  
   - âœ… *Safe*  
   - âš ï¸ *Harmful*  
   - ğŸš¨ *Dangerous*  
4. Based on the result, the app offers clear guidance, such as:  
   - â€œBlock & reportâ€  
   - â€œSave as evidenceâ€  
   - â€œContact local helplineâ€  

---

## âœ¨ Main Features

- **AI Harassment Checker**  
  Paste text â†’ click â€œCheckâ€ â†’ get a score + category.  

- **Save Evidence**  
  Save harmful or dangerous messages to a secure list for reference.  

- **Resources Section**  
  A static list of helplines and support services (e.g., for Tanzania) to provide real-world help.  

- **History Page**  
  View previously saved reports / messages, so users can revisit or export them.

---

## ğŸ”— Live App

You can access the live version of the app here:  
[SpeakSafe AI on Lovable](https://speak-safe-spot.lovable.app)

---

## ğŸ› ï¸ Technology Stack

- **Frontend:** React + Tailwind CSS  
- **Backend:** Node.js + Express  
- **Database:** MongoDB  
- **AI / NLP:** Toxicity detection via a hosted API (e.g., Hugging Face) or OpenAI  
- **Hosting:** Your Lovable app + any backend host (e.g., Render, Heroku)

---

## ğŸ›¡ï¸ Privacy & Safety Considerations

- The app **does not require personal registration** â€” users can use it anonymously.  
- Messages labeled as â€œharmfulâ€ or â€œdangerousâ€ can be saved locally in a **secure way** via the appâ€™s history.  
- Sensitive data should be encrypted if stored (depending on your implementation).  
- Provide clear disclaimers that SpeakSafe AI is **not a substitute for legal help or emergency services** â€” and encourage users to contact trusted resources or professionals when needed.

---

## ğŸ“ˆ Future Improvements

Here are some ideas for future versions of SpeakSafe AI:

- Add language support for more African languages  
- Enable users to export saved evidence in a shareable format  
- Integrate a â€œreport to authorities / NGOsâ€ feature  
- Add real-time sentiment tracking or conversation analysis  
- Build a mobile PWA (Progressive Web App) for offline support  
- Introduce user accounts (optional) with encrypted storage  

---

## ğŸ™Œ Contributing

Feel free to contribute to SpeakSafe AI! Whether by:

- Improving the UI / UX  
- Adding new language models or toxicity classifications  
- Updating the helpline / resources list  
- Enhancing data privacy & encryption features  

1. Fork the repo  
2. Create a feature branch  
3. Make your changes  
4. Submit a pull request  

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE) â€” feel free to use, modify, and distribute it.

---

## ğŸ“ Contact

If you want to reach out, you can email / message me at:  
**[Your Name]** â€” *your.email@example.com*

---

Welcome to SpeakSafe AI â€” building safer digital spaces, one message at a time.  
